{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08df309d-5979-4df9-964f-fc9b3da63ec5",
   "metadata": {},
   "source": [
    "# Aviation Data Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf59667-1b0a-4891-89d9-c36736ef3c82",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4bd42-6e07-488d-a3ed-74d89447ac42",
   "metadata": {},
   "source": [
    "In this notebook, I shall focus on cleaning and analyzing data from the `AviationData.csv` dataset. This particular dataset was provided by the National Safety and Transport Board and it contains information about aviation accidents from the year 1962 to the year 2023. The goal is to identify patterns, clean missing values, eliminate outliers, and prepare the data for further analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54709795-91c8-43ca-94cd-f3a2a00f3aa7",
   "metadata": {},
   "source": [
    "## The Task at Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9720d5c-cc50-47f7-b05e-5d3039b3dd83",
   "metadata": {},
   "source": [
    "The `AviationData.csv` dataset contains information about aviation accidents, but it requires *cleaning* and *preprocessing* due to missing values, inconsistencies, and potential outliers. The cleaned data will help:\n",
    "- Identify key patterns in accidents and their causes.\n",
    "- Understand the impact of weather and other conditions on accidents.\n",
    "- Prepare a high-quality dataset for detailed analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b14a6-852f-478f-b035-a8da8c7f2f39",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ea7c7-cbe2-4aab-9148-bac4d30d968f",
   "metadata": {},
   "source": [
    "1) To understand the structure of the dataset.\n",
    "2) Clean missing values and ensure consistency.\n",
    "3) Perform feature engineering for better insights.\n",
    "4) Aggregate and analyze key data points.\n",
    "5) Save the cleaned dataset for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fc0459-f63b-4415-8264-6584198dcbee",
   "metadata": {},
   "source": [
    "## 1. Import libraries and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639be8e-01cb-4b26-8e2a-7e5237d4992e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/jackl/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Start by Importing libraries commonly used for data analysis and visualization with their corresponding aliases\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('AviationData.csv', encoding='ISO-8859-1', low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01766063-eb48-4521-814a-4f099f294884",
   "metadata": {},
   "source": [
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ad0f6-deb6-431a-8b7a-7b791d0a808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())  # For numerical columns\n",
    "\n",
    "#Total missing values in each column\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(missing_values)\n",
    "\n",
    "#Unique values in a few categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols[:5]:  # Check the first 5 categorical columns\n",
    "    print(f\"\\nUnique values in '{col}':\")\n",
    "    print(df[col].unique())\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c9d3e-2b12-4f2a-a890-954c002860e4",
   "metadata": {},
   "source": [
    "## 3. Remove Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6ecb0-8e1c-41a1-a3de-e2f9906a6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get column names\n",
    "print(df.columns)\n",
    "\n",
    "# Drop specific irrelevant columns\n",
    "df = df.drop(['Event.Id', 'Airport.Code', 'Accident.Number', 'FAR.Description', 'Schedule'],axis=1)\n",
    "print(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b990d-d730-440b-9042-f168cfb15cbb",
   "metadata": {},
   "source": [
    "## 4. Change Column Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5bd15-75ab-487b-b76b-2d4c5c9c4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the columns to look neater and increased readability replace the dots with whitespaces\n",
    "df.columns = df.columns.str.replace(\".\", \" \")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2e7eb-f0b2-478e-bc62-499fde2fa9d5",
   "metadata": {},
   "source": [
    "## 5. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620f330-1a6d-4b1b-b94a-abc53bcaa87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the dataset contains missing values\n",
    "print(df.isnull().sum().any())\n",
    "\n",
    "#If so how many missing values do we have in each column?\n",
    "df.isna().sum()\n",
    "\n",
    "#Handle missing values in numeric using median\n",
    "for column in df.select_dtypes(include=[\"number\"]).columns:\n",
    "     df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "# Handle categorical columns with missing values using mode\n",
    "for column in df.select_dtypes(exclude=[\"number\"]).columns:\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "#Confirm that no missing values left\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3fcfa-eda1-4cef-a491-05d39997946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm that there are no missing values left from the entire datset\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f816fd5-cbc9-4573-a957-b62702a5470c",
   "metadata": {},
   "source": [
    "## 6. Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50ea40-22b8-4561-9556-01c70374a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicates\n",
    "duplicates = df[df.duplicated()]\n",
    "print(duplicates)\n",
    "\n",
    "#remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#confirm removal\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe188d-8b72-46e4-88e1-d3bbe73a888f",
   "metadata": {},
   "source": [
    "## 7. Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1784d7-00c3-4775-8a7b-c9dbda8c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16ecee-449e-4606-806b-c66e073cdebe",
   "metadata": {},
   "source": [
    "## 9. Get Rid of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "34d05452-b6ef-4e46-9573-609a50673eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select numeric columns from the dataframe\n",
    "numeric_columns = df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "#Calculate Q1, Q3 and IQR for the numeric columns\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "\n",
    "#Define lower bounds and upper bounds for outlier removal\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "#Filter data to keep only numbers within the IQR bounds\n",
    "no_outliers = df[(df[numeric_columns] >= lower_bound) & (df[numeric_columns] <= upper_bound)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037568d4-1f3c-4aa4-98a7-6b8dd6fa5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d481c8-fb00-4805-8986-e1f612d3fb22",
   "metadata": {},
   "source": [
    "## 7. Parse and extract date information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f7426-bd1e-4cd0-87fb-c884b12ba939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the column names\n",
    "#print(df.columns)\n",
    "\n",
    "# Parse date columns\n",
    "df['Event Date'] = pd.to_datetime(df['Event Date'], errors='coerce', dayfirst=False)\n",
    "df['Publication Date'] = pd.to_datetime(df['Publication Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Extract year, month, and day from Event.Date\n",
    "df['Event Year'] = df['Event Date'].dt.year\n",
    "df['Event Month'] = df['Event Date'].dt.month\n",
    "df['Event Day'] = df['Event Date'].dt.day\n",
    "\n",
    "print(df.head())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5ce6e-5426-49b9-86ff-715b76e0b0f5",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b75d28-a532-446c-ae5e-12d1b02b9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine injury columns into a single metric\n",
    "df['Total Injuries'] = (\n",
    "    df['Total Fatal Injuries'] +\n",
    "    df['Total Serious Injuries'] +\n",
    "    df['Total Minor Injuries'] +\n",
    "    df['Total Uninjured']\n",
    ")\n",
    "\n",
    "# Compare the columns (use total_injuries instead of total.injuries.calculated)\n",
    "print((df['Total Injuries'] == df['Total Injuries']).all())\n",
    "\n",
    "# Standardize 'Weather.Condition' values\n",
    "if 'Weather Condition' in df.columns:\n",
    "    df['Weather Condition'] = df['Weather Condition'].replace({'UNK': 'Unknown'}).str.title()\n",
    "\n",
    "# Check the updated output\n",
    "print(df[['Total Injuries', 'Weather Condition']].head())\n",
    "\n",
    "# Cap injury values at the 99th percentile\n",
    "for col in ['Total Fatal Injuries', 'Total Serious Injuries', 'Total Minor Injuries', 'Total Injuries']:\n",
    "    upper_limit = df[col].quantile(0.99)\n",
    "    df[col] = np.where(df[col] > upper_limit, upper_limit, df[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93d5ed-714c-4c7b-a780-8e87e80bc25d",
   "metadata": {},
   "source": [
    "## Weather Condition (Fill 'UNK' with 'Unknown'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a77b33-5b72-45d9-8c8c-24dd14714e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weather Condition'] = df['Weather Condition'].replace({'UNK': 'Unknown'}).str.title()\n",
    "df['Weather Condition'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a44cb3-876e-4413-8721-56b8895b23bf",
   "metadata": {},
   "source": [
    "## Filling missing values in the 'Number.of.Engines' column with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b70e6-d53b-4331-9cdc-7efb7fcb2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of Engines'] = df['Number of Engines'].fillna(df['Number of Engines'].median())\n",
    "df['Number of Engines']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de228de-f2fc-4d3c-ac6b-a5897b03a6ba",
   "metadata": {},
   "source": [
    "## Categorical Columns (Fill with Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c690af34-9033-4f69-ac77-f9c7b2952f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32654875-861b-48ae-9657-855ccfd8775d",
   "metadata": {},
   "source": [
    "## Top Aircraft Makes (Categorize Others as 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "79d436a8-25df-4d1e-afc8-6051e5e88a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_makes = df['Make'].value_counts().nlargest(10).index\n",
    "df['Make'] = df['Make'].apply(lambda x: x if x in top_makes else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d5a69-1637-48b3-91fe-4f0030a0db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['weather.condition'].value_counts())\n",
    "print(df['injury.severity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee30ff-4734-4f4b-b3af-72409b7b554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)  # Check the number of rows and columns\n",
    "print(df.head())  # View the first few rows of the DataFrame\n",
    "df['Publication Date'] = df['Publication Date'].fillna(method='ffill')\n",
    "df['Publication Date'] = df['Publication Date'].ffill()\n",
    "df['Publication Date'] = df['Publication Date'].bfill() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1c67b-e931-44a5-9968-d55e9ee2d24a",
   "metadata": {},
   "source": [
    "## Confirm the file's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec817e-095d-4074-8e95-3a2cbbc1c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Final structure\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67a856-2c30-4df6-9254-b18d7185593b",
   "metadata": {},
   "source": [
    "## Save the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "06206b84-996d-4593-9283-99353bea8bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataset\n",
    "df.to_csv('Cleaned_AviationDataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977cafe-0d68-4bd6-a243-170fa8c62517",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd32b0d-4a8f-40b6-b47c-796a9a7d0c42",
   "metadata": {},
   "source": [
    "This notebook involved cleaning and analyzing aviation data. Missing values were handled, features were engineered, and outliers were addressed to ensure data quality. The cleaned dataset is now ready for further analysis or modeling.\n",
    "\n",
    "The cleaned dataset is saved and ready for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b276be-a00a-4100-8175-2642ef89cf7f",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3859f-3823-462a-90f4-7ad6f88ca6be",
   "metadata": {},
   "source": [
    "1) Conduct advanced analysis (e.g., predictive modeling or clustering).\n",
    "2) Explore temporal trends in aviation incidents.\n",
    "3) Investigate relationships between aircraft types and injury severity.\n",
    "4) Use the cleaned data to come up with an interactive dashboard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
